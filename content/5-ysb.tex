\section{Yahoo Streaming Benchmark (YSB)\cite{ysb}}
The Yahoo Streaming Benchmark is a single dataflow benchmark created by Yahoo in 2015. Of the three benchmark suites implemented in this thesis, it is the one most widely used in the industry. The original implementation includes support for Storm, Spark, Flink, and Apex. \\

\imagefigure[ysb]{images/ysb-graphs.pdf}{A graph of the dataflow described by YSB.}

The dataflow used in the benchmark is illustrated in \autoref{figure:ysb}. Its purpose is to count ad hits for each ad campaign. Events arrive from Kafka in JSON string format, where each event is a flat object with the following fields:

\begin{itemize}
\item \code{user_id} A UUID identifying the user that caused the event.
\item \code{page_id} A UUID identifying the page on which the event occurred.
\item \code{ad_id} A UUID for the specific advertisement that was interacted with.
\item \code{ad_type} A string, one of ``banner'', ``modal'', ``sponsored-search'', ``mail'', and ``mobile''.
\item \code{event_type} A string, one of ``view'', ``click'', and ``purchase''.
\item \code{event_time} An integer timestamp in milliseconds of the time the event occurred.
\item \code{ip_address} A string of the user's IP address.
\end{itemize}

The dataflow proceeds as follows: the first operator parses the JSON string into an internal object. Irrelevant events are then filtered out, and only ones with an \code{event_type} of ``view'' are retained. Next, all fields except for \code{ad_id} and \code{event_time} are dropped. Then, a lookup in a table mapping \code{ad_id}s to \code{campaign_id}s is done to retrieve the relevant \code{campaign_id}. Yahoo describes this step as a join, which is inaccurate, as only one end of this ``join'' is streamed, whereas the other is present as a table stored in Redis. Next the events are put through a ten seconds large hopping window. The number of occurrences of each \code{campaign_id} within each window are finally counted and stored back into Redis.

\subsection{Implementation}
\subsubsection{Data Generation}
As the data used in YSB is fairly straight forward, we created our own data generator. The generator creates random \code{user_id}s, \code{page_id}s, and \code{ip_address}es. Since those fields aren't actually touched by the query, the precise data should not make any difference. The \code{ad_type} and \code{event_type} are randomly chosen from the specified sets. The \code{ad_id} is chosen from a randomly generated table of \code{ad_id}s to \code{campaign_id}s. This table consists of 100 campaigns with 10 ads each, as specified by YSB. The most interesting field is the \code{event_time} which is monotonically stepped in milliseconds according to how many events per second should be generated. \\

This is all in line with the implementation of the data generator found in the original YSB repository (\code{data/src/setup/core.clj}). Curiously, their implementation does include parts to skew the time stamps and randomise them, but they are not actually used. Like many other implementations of YSB, we also do not rely on Redis for the \code{ad_id} to \code{campaign_id} lookup, and instead keep this small table in memory of our query. \\

The primary purpose of implementing our own generation for YSB is to find a short path to testing the query. While it is possible to add Kafka as an event source, generating the data directly in memory allows us to more easily test various configurations and explore datasets that would take up massive amounts of space to store ahead of time.

\subsubsection{Query}
\begin{listing}[H]
  \inputminted[firstline=82,lastline=92]{rust}{benchmarks/src/ysb.rs}
  \caption{Dataflow implementation of the YSB benchmark.}
  \label{lst:ysb}
\end{listing}

The implementation of the query is rather straightforward. The only step of the dataflow graph not directly represented here as an operator is the translation of the JSON string into the event object. We skip out on this as the translation is done on the data feeding end in order to use the event's \code{event_time} field to manage the corresponding epoch of the event. Each epoch corresponds to a real-time of one second. \\

The second \code{map} operator is responsible for performing the lookup in the \code{campaign_id} table. Instead of the original Redis query, we use a simple hash-table lookup. A copy of the table is kept locally in memory of each worker. Since we don't make use of any of the remaining event fields after this step, we only emit the \code{campaign_id}, rather than a tuple of the event's fields.

\subsection{Evaluation}
\latencyfigure[ysb]{
  \addplot table[y index=0, x index=5] {data/latency.csv};
}{Linlog plot of the Latency vs Rate.}

\scalingfigure[ysb]{
  \addplot table[x index=0, y index=5] {data/scaling.csv};
}{Linlog plot of the scaling behaviour.}

\cdffigure[ysb]{
  \addplot table[y index=0, x index=5] {data/cdf.csv};
}{CDF latency plot.}

\subsection{Remarks}
Compared to the queries shown in NEXMark, the Yahoo Streaming Benchmark is exceedingly simple. It also includes some rather odd requirements that were most likely simply specific to Yahoo's internal use-case, rather than born out of consideration for what would make a good benchmark. Most notably the lookup in Redis would present a significant bottleneck for most modern streaming systems, and the required JSON deserialisation step will lead to the benchmark mostly testing the JSON library's speed, rather than the streaming system's actual performance in processing the data. \\

Disregarding the Redis look up and the deserialisation, the only remaining operation the benchmark performs is a windowed reduction, as the projection can be mostly disregarded. This means that the benchmark does not add much complexity over a very basic word count test. Thus we believe it is neither representative of typical streaming systems applications, nor extensive enough in testing the system's expressiveness or capabilities.

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../thesis"
%%% TeX-engine: luatex
%%% TeX-command-extra-options: "-shell-escape"
%%% End:
