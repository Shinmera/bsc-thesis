\section{NEXMark Benchmark}\label{section:nexmark}
NEXMark\cite{nexmark} is an evolution of the XMark benchmark. XMark was initially designed for relational databases and defines a small schema for an online auction house. NEXMark builds on this idea and presents a schema of three concrete tables, and a set of queries to run in a streaming sense. NEXMark attempts to provide a benchmark that is both extensive in its use of operators, and close to a real-world application by being grounded in a well-known problem. \\

The original benchmark proposed by Tucker et al. was adopted and extended by the Apache Foundation for their use in Beam\cite{nexmark-beam}, a system intended to provide a general API for a variety of streaming systems. We will follow the Beam implementation, as it is the most widely adopted one, despite having several differences to the benchmark originally outlined in the paper. See \autoref{section:nexmark-remarks} for an outline of the differences we found. Similar to HiBench and YSB, NEXMark as implemented by Beam does not concern itself with questions of scaling, load bearing, and fault tolerance, focusing solely on the latency aspect. \\

The benchmark defines the following queries:

\begin{enumerate}
  \setcounter{enumi}{-1}
\item \tb{Pass-Through} This is similar to HiBench's Identity query and should just output the received data.
  \imagefigure[nexmark-0]{images/nexmark-0.pdf}{NEXMark's Query 0.}
\item \tb{Currency Conversion} Output bids on auctions, but translate the bid price to Euro.
  \imagefigure[nexmark-1]{images/nexmark-1.pdf}{NEXMark's Query 1.}
\item \tb{Selection} Filter to auctions with a specific set of IDs.
  \imagefigure[nexmark-2]{images/nexmark-2.pdf}{NEXMark's Query 2.}
\item \tb{Local Item Suggestion} Output persons that are outputting auctions in particular states.
  \imagefigure[nexmark-3]{images/nexmark-3.pdf}{NEXMark's Query 3.}
\item \tb{Average Price for a Category} Compute the average auction price in a category for all auctions that haven't expired yet.
  \imagefigure[nexmark-4]{images/nexmark-4.pdf}{NEXMark's Query 4.}
\item \tb{Hot Items} Show the auctions with the most bids over the last hour, updated every minute.
  \imagefigure[nexmark-5]{images/nexmark-5.pdf}{NEXMark's Query 5.}
\item \tb{Average Selling Price by Seller} Compute the average selling price for the last ten closed auctions per auctioner.
  \imagefigure[nexmark-6]{images/nexmark-6.pdf}{NEXMark's Query 6.}
\item \tb{Highest Bid} Output the auction and bid with the highest price in the last minute.
  \imagefigure[nexmark-7]{images/nexmark-7.pdf}{NEXMark's Query 7.}
\item \tb{Monitor New Users} Show persons that have opened an auction in the last 12 hours.
  \imagefigure[nexmark-8]{images/nexmark-8.pdf}{NEXMark's Query 8.}
\item \tb{Winning Bids} Compute the winning bid for an auction. This is used in queries 4 and 6.
  \imagefigure[nexmark-9]{images/nexmark-9.pdf}{NEXMark's Query 9.}
\item \tb{Log to GCS} Output all events to a GCS file, which is supposed to illustrate large side effects.
  \imagefigure[nexmark-10]{images/nexmark-10.pdf}{NEXMark's Query 10.}
\item \tb{Bids in a Session} Show the number of bids a person has made in their session.
  \imagefigure[nexmark-11]{images/nexmark-11.pdf}{NEXMark's Query 11.}
\item \tb{Bids within a Window} Compute the number of bids a user makes within a processing-time constrained window.
  \imagefigure[nexmark-12]{images/nexmark-12.pdf}{NEXMark's Query 12.}
\end{enumerate}

The queries are based on three types of events that can enter the system: \code{Person}, \code{Auction}, and \code{Bid}. Their fields are as follows:

\paragraph*{Person}
\begin{itemize}
\item \code{id} A person-unique integer ID.
\item \code{name} A string for the person's full name.
\item \code{email_address} The person's email address as a string.
\item \code{credit_card} The credit card number as a 19-letter string.
\item \code{city} One of several US city names as a string.
\item \code{state} One of several US states as a two-letter string.
\item \code{date_time} A millisecond timestamp for the event origin.
\end{itemize}

\paragraph*{Auction}
\begin{itemize}
\item \code{id} An auction-unique integer ID.
\item \code{item_name} The name of the item being auctioned.
\item \code{description} A short description of the item.
\item \code{initial_bid} The initial bid price in cents.
\item \code{reserve} The minimum price for the auction to succeed.
\item \code{date_time} A millisecond timestamp for the event origin.
\item \code{expires} A UNIX epoch timestamp for the expiration date of the auction.
\item \code{seller} The ID of the person that created this auction.
\item \code{category} The ID of the category this auction belongs to.
\end{itemize}

\paragraph*{Bid}
\begin{itemize}
\item \code{auction} The ID of the auction this bid is for.
\item \code{bidder} The ID of the person that placed this bid.
\item \code{price} The price in cents that the person bid for.
\item \code{date_time} A millisecond timestamp for the event origin.
\end{itemize}

\subsection{Implementation}
\subsubsection{Data Generation}
In order to be able to run the benchmark outside of the Beam framework, we had to replicate their generator. For this we translated the original Java sources of the generator (\code{sdks/java/nexmark/src/main/java/org/apache/beam/sdk/nexmark/sources/generator}) into Rust. Unfortunately it appears that the Beam generator has a hard constraint on its rate due to a lack of precision, and can thus only output at most 2M events per second. In our tests the system did not congest at these rates, so we had to modify the generation to be more precise, and allow higher rates. This may have changed the generation in subtle ways that we are not aware of. If it is indeed possible to output more than 2M events per second in the original generator, we could not figure out how to make it do so due to the lack of proper documentation. \\

We have validated our generator against Beam's via manual data output comparison. It should function identical to Beam's setup and our results should thus be accurate even outside of Beam's framework.

\subsubsection{Queries}
\paragraph{Query 0}
\begin{listing}[H]
  \inputminted[firstline=449,lastline=449]{rust}{benchmarks/src/nexmark.rs}
  \caption{Implementation for NEXMark's Query 0}
  \label{lst:nexmark-query0}
\end{listing}

\paragraph{Query 1}\label{sec:query1}
\begin{listing}[H]
  \inputminted[firstline=474,lastline=476]{rust}{benchmarks/src/nexmark.rs}
  \caption{Implementation for NEXMark's Query 1}
  \label{lst:nexmark-query1}
\end{listing}

Technically we could have implemented this with a single \code{filter_map}, but keeping the filtering and the query computation separate is a tad cleaner.

\paragraph{Query 2}
\begin{listing}[H]
  \inputminted[firstline=508,lastline=511]{rust}{benchmarks/src/nexmark.rs}
  \caption{Implementation for NEXMark's Query 2}
  \label{lst:nexmark-query2}
\end{listing}

Similar to \autoref{sec:query1}, this could have been done with a single \code{filter_map}, but splitting the work up over multiple operators like this makes the code much easier to read.

\paragraph{Query 3}
\begin{listing}[H]
  \inputminted[firstline=542,lastline=551]{rust}{benchmarks/src/nexmark.rs}
  \caption{Implementation for NEXMark's Query 3}
  \label{lst:nexmark-query3}
\end{listing}

This query introduces the first join. Since we need to continuously report on new auctions, we need to retain all persons records indefinitely using the \code{left_join}.

\paragraph{Query 4}\label{sec:query4}
\begin{listing}[H]
  \inputminted[firstline=582,lastline=583]{rust}{benchmarks/src/nexmark.rs}
  \caption{Implementation for NEXMark's Query 4}
  \label{lst:nexmark-query4}
\end{listing}

The bulk of the work for this query is factored out into the code from \autoref{sec:query9}. All that remains to do afterwards is to perform an averaging reduce for each category. \\

It is important to note here that the Beam implementation diverges from the original NEXMark specification by performing a sliding window before the reduction. This change is not documented anywhere. We have decided not to follow this change in our implementation.

\paragraph{Query 5}
\begin{listing}[H]
  \inputminted[firstline=611,lastline=620]{rust}{benchmarks/src/nexmark.rs}
  \caption{Implementation for NEXMark's Query 5}
  \label{lst:nexmark-query5}
\end{listing}

Query 5 introduces the first use of windowing in NEXMark, and requires a sliding window to boot. The way the filtering for the most bid auction is done may seem a bit odd. Essentially we perform two reductions, once to perform a count of all bids within the epoch, and another time to determine the overall maximum count within the epoch. We then join the two together and filter to only retain the auction that corresponds to the maximum count. \\

Note that the implementation of this query in Beam differs from our interpretation of the query as described in the original NEXMark paper. As it stands now it emits auctions whose bid count is maximal within the window, whereas the initial query description seems to emit events if and only if there is only one auction mentioned by bids within the window. We consider the initial query to be bogus, since it is practically impossible for an epoch to only contain bids of a single auction.

\paragraph{Query 6}
\begin{listing}[H]
  \inputminted[firstline=645,lastline=647]{rust}{benchmarks/src/nexmark.rs}
  \caption{Implementation for NEXMark's Query 6}
  \label{lst:nexmark-query6}
\end{listing}

Like for \autoref{sec:query4} most of the work is factored out into the code from \autoref{sec:query9}. This query is also the only one that makes use of partitioning. The partitioning operator works slightly different from the rest of the windowing-like operators in that it does not unfold its contents into the data stream. Since each epoch might encompass a multitude of partitions, we need to keep the partition's data in vectors. In order to average the data in those records we then have to manually reduce within the map operator.

\paragraph{Query 7}
\begin{listing}[H]
  \inputminted[firstline=680,lastline=686]{rust}{benchmarks/src/nexmark.rs}
  \caption{Implementation for NEXMark's Query 7}
  \label{lst:nexmark-query7}
\end{listing}

We make use of the generic reduce operator here in order to quickly determine the maximum priced bid within the window. This could have also been done with an implementation of the \code{PartialOrd} trait on \code{Bid} and by using the \code{maximize_by} operator followed by a map.

\paragraph{Query 8}
\begin{listing}[H]
  \inputminted[firstline=719,lastline=728]{rust}{benchmarks/src/nexmark.rs}
  \caption{Implementation for NEXMark's Query 8}
  \label{lst:nexmark-query8}
\end{listing}

Query 8 is mildly interesting due to the two windows that are joined up. However, due to Timely's epoch based data handling, the synchronisation between the two windows is free.

\paragraph{Query 9}\label{sec:query9}
\begin{listing}[H]
  \inputminted[firstline=751,lastline=788]{rust}{benchmarks/src/nexmark.rs}
  \caption{Implementation for NEXMark's Query 9}
  \label{lst:nexmark-query9}
\end{listing}

Due to the curious constraints on real-time filtering during a join we opted for implementing a custom operator for this query. The operator proceeds by computing the epoch on which each auction it sees is going to expire. It then remembers the auction for that epoch and schedules a notification to occur at that time. This is useful since we will only be able to emit the joined bid price and auction once the expiry time has been reached and we are sure that we've seen all bids. \\

On the bid side we simply store each bid on a map associated with the auction it belongs to. \\

Once we have reached an expiry time, we iterate through each expired auction. We then iterate through all of the auction's bids to filter out invalid ones and compute the maximum bid price. Finally we output the auction associated with the computed price.

\paragraph{Query 10}
We did not implement Query 10 as we felt it did not reflect a useful case outside of the very specific and particular application of writing to a Google Cloud Storage file.

\paragraph{Query 11}
\begin{listing}[H]
  \inputminted[firstline=833,lastline=836]{rust}{benchmarks/src/nexmark.rs}
  \caption{Implementation for NEXMark's Query 11}
  \label{lst:nexmark-query11}
\end{listing}

Since we know for certain that a bid's \code{date_time} stamp corresponds to an epoch at the second level, we can simply compute the session a bid corresponds to according to that stamp.

\paragraph{Query 12}
\begin{listing}[H]
  \inputminted[firstline=860,lastline=866]{rust}{benchmarks/src/nexmark.rs}
  \caption{Implementation for NEXMark's Query 12}
  \label{lst:nexmark-query12}
\end{listing}

We assume that epochs start at \code{0}, so we can use a timer to measure the elapsed wall clock time since the beginning of the dataflow run and correlate that to a real-time session. Note that for this to work at all, epochs need to be correlated to real-time seconds as well, and a closed-loop experiment with no regards for time constraints will crash.

\subsection{Evaluation}
We ran our experiments on an AMD Opteron 6378 2.4GHz 64bit machine with a total of 32 Cores and 504GB RAM. This machine is known to exhibit strange scaling behaviour due to non-uniform memory access patterns. You can see this behaviour in the \hyperref[figure:ysb-scaling]{scaling plot} at 16 workers. \\

Our measurement procedure involved a closed-loop data feed, meaning each epoch was run to completion before a new epoch with a new round of data was started. We only measured data flow execution time, excluding data generation time. Each measurement was gathered using 300 epochs of data. \\

\latencyfigure[nex]{16}{6,7,8,9,10,11,12,13,14,15,16}{Q0, Q1, Q2, Q3, Q4, Q5, Q6, Q7, Q8, Q9, Q11}
\latencyfigure[nex]{32}{6,7,8,9,10,11,12,13,14,15,16}{Q0, Q1, Q2, Q3, Q4, Q5, Q6, Q7, Q8, Q9, Q11}
\scalingfigure[nex]{10000000}{6,7,8,9,10,11,12,13,14,15,16}{Q0, Q1, Q2, Q3, Q4, Q5, Q6, Q7, Q8, Q9, Q11}
\cdffigure[nex]{32}{10000000}{6,7,8,9,10,11,12,13,14,15,16}{Q0, Q1, Q2, Q3, Q4, Q5, Q6, Q7, Q8, Q9, Q11}

\subsection{Remarks}\label{section:nexmark-remarks}
NEXMark presents the most extensive benchmark of the three we have investigated. It shows a number of different applications that involve a variety of different operators and configurations. Unlike the other two, NEXMark was a research project designed to present a useful benchmark for streaming systems. As such it has a formal specification of the datastructures and queries involved, and presents a reference data generation implementation. These are vital pieces if it should be possible for third-parties to implement the benchmark and compare results. \\

However, the only widespread use of the benchmark is with Apache's Beam system. The Beam implementors made several relatively severe changes to the benchmark. First, they implemented their own generator that has almost nothing in common with the original generator. Second, they added more queries whose precise behaviour and purpose is not formally specified or documented anywhere. Third, they changed the size of the windows to be merely ten seconds, rather than the minutes and hours the original specification sets. \\

We assume the idea behind Beam's implementation is that, in order to offer comparable benchmarks for systems, you would simply have to write a backend for your system in Beam. This however is not trivially achievable, and also will not actually produce results that will properly reflect your system, as the benchmark will implicitly measure and compare not just your system on its own, but also the backend you wrote for Beam and how well it translates queries. \\

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../thesis"
%%% TeX-engine: luatex
%%% TeX-command-extra-options: "-shell-escape"
%%% End:
